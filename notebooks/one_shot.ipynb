{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "955f6e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-28 10:35:22.474216: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-28 10:35:22.474269: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0d06cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.003\n",
    "meta_step_size = 0.25\n",
    "\n",
    "inner_batch_size = 25\n",
    "eval_batch_size = 25\n",
    "\n",
    "meta_iters = 2000\n",
    "eval_iters = 5\n",
    "inner_iters = 4\n",
    "\n",
    "eval_interval = 1\n",
    "train_shots = 20\n",
    "shots = 5\n",
    "classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4db6fc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=int32, numpy=0>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=1>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=0>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=1>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=1>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(labels, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "771afb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    # This class will facilitate the creation of a few-shot dataset\n",
    "    # from the Omniglot dataset that can be sampled from quickly while also\n",
    "    # allowing to create new labels at the same time.\n",
    "    def __init__(self, training):\n",
    "        # Download the tfrecord files containing the omniglot data and convert to a\n",
    "        # dataset.\n",
    "        split = \"train\" if training else \"test\"\n",
    "        ds = tfds.load(\"omniglot\", split=split, as_supervised=True, shuffle_files=False)\n",
    "        # Iterate over the dataset to get each individual image and its class,\n",
    "        # and put that data into a dictionary.\n",
    "        self.data = {}\n",
    "\n",
    "        def extraction(image, label):\n",
    "            # This function will shrink the Omniglot images to the desired size,\n",
    "            # scale pixel values and convert the RGB image to grayscale\n",
    "            image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "            image = tf.image.rgb_to_grayscale(image)\n",
    "            image = tf.image.resize(image, [28, 28])\n",
    "            return image, label\n",
    "\n",
    "        for image, label in ds.map(extraction):\n",
    "            image = image.numpy()\n",
    "            label = str(label.numpy())\n",
    "            if label not in self.data:\n",
    "                self.data[label] = []\n",
    "            self.data[label].append(image)\n",
    "        self.labels = list(self.data.keys())\n",
    "        print(self.labels)\n",
    "\n",
    "    def get_mini_dataset(\n",
    "        self, batch_size, repetitions, shots, num_classes, split=False\n",
    "    ):\n",
    "        temp_labels = np.zeros(shape=(num_classes * shots))\n",
    "        temp_images = np.zeros(shape=(num_classes * shots, 28, 28, 1))\n",
    "        if split:\n",
    "            test_labels = np.zeros(shape=(num_classes))\n",
    "            test_images = np.zeros(shape=(num_classes, 28, 28, 1))\n",
    "\n",
    "        # Get a random subset of labels from the entire label set.\n",
    "        label_subset = random.choices(self.labels, k=num_classes)\n",
    "        for class_idx, class_obj in enumerate(label_subset):\n",
    "            # Use enumerated index value as a temporary label for mini-batch in\n",
    "            # few shot learning.\n",
    "            temp_labels[class_idx * shots : (class_idx + 1) * shots] = class_idx\n",
    "            # If creating a split dataset for testing, select an extra sample from each\n",
    "            # label to create the test dataset.\n",
    "            if split:\n",
    "                test_labels[class_idx] = class_idx\n",
    "                images_to_split = random.choices(\n",
    "                    self.data[label_subset[class_idx]], k=shots + 1\n",
    "                )\n",
    "                test_images[class_idx] = images_to_split[-1]\n",
    "                temp_images[\n",
    "                    class_idx * shots : (class_idx + 1) * shots\n",
    "                ] = images_to_split[:-1]\n",
    "            else:\n",
    "                # For each index in the randomly selected label_subset, sample the\n",
    "                # necessary number of images.\n",
    "                temp_images[\n",
    "                    class_idx * shots : (class_idx + 1) * shots\n",
    "                ] = random.choices(self.data[label_subset[class_idx]], k=shots)\n",
    "\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            (temp_images.astype(np.float32), temp_labels.astype(np.int32))\n",
    "        )\n",
    "        dataset = dataset.shuffle(100).batch(batch_size).repeat(repetitions)\n",
    "        if split:\n",
    "            return dataset, test_images, test_labels\n",
    "        return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86812b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['617', '672', '325', '177', '247', '832', '824', '803', '294', '921', '609', '569', '20', '308', '395', '179', '573', '620', '551', '600', '204', '778', '217', '919', '751', '528', '382', '708', '524', '847', '35', '37', '41', '234', '267', '769', '881', '36', '652', '199', '591', '592', '674', '486', '497', '155', '111', '958', '754', '326', '706', '647', '788', '73', '130', '621', '537', '494', '934', '638', '896', '918', '776', '596', '332', '515', '646', '89', '729', '523', '742', '125', '670', '748', '678', '932', '272', '836', '945', '557', '796', '781', '12', '804', '744', '624', '119', '846', '608', '854', '837', '525', '483', '200', '777', '509', '659', '916', '540', '759', '632', '858', '189', '95', '963', '27', '154', '279', '588', '861', '880', '261', '310', '464', '175', '565', '521', '501', '213', '547', '433', '468', '723', '582', '137', '727', '567', '757', '139', '947', '726', '953', '649', '771', '407', '653', '599', '943', '779', '794', '147', '74', '867', '750', '721', '132', '79', '260', '470', '281', '773', '459', '656', '458', '877', '14', '890', '673', '42', '610', '171', '393', '587', '417', '243', '235', '81', '67', '362', '319', '767', '519', '143', '648', '605', '942', '612', '284', '516', '208', '476', '84', '210', '585', '226', '868', '699', '138', '684', '930', '280', '262', '841', '505', '153', '359', '874', '222', '860', '873', '209', '914', '686', '40', '488', '242', '377', '331', '552', '635', '856', '685', '197', '126', '833', '798', '70', '627', '894', '606', '615', '538', '215', '162', '7', '623', '575', '256', '426', '98', '129', '908', '823', '855', '895', '645', '810', '366', '594', '87', '354', '746', '795', '121', '355', '899', '230', '109', '97', '161', '792', '500', '558', '248', '923', '862', '920', '816', '887', '830', '490', '157', '298', '188', '613', '192', '151', '576', '69', '892', '53', '536', '435', '383', '63', '52', '879', '636', '402', '805', '651', '375', '66', '660', '482', '231', '164', '9', '104', '580', '492', '176', '457', '17', '761', '532', '640', '514', '607', '183', '844', '348', '313', '508', '345', '705', '719', '144', '142', '419', '58', '31', '655', '954', '542', '909', '561', '76', '936', '303', '711', '682', '178', '650', '550', '384', '276', '713', '117', '181', '363', '203', '598', '820', '252', '148', '271', '61', '487', '461', '54', '534', '845', '901', '438', '661', '541', '864', '160', '353', '128', '170', '421', '876', '367', '853', '439', '933', '365', '245', '180', '59', '102', '115', '926', '343', '187', '480', '398', '679', '952', '462', '108', '18', '941', '469', '249', '6', '50', '93', '316', '428', '255', '702', '859', '554', '444', '4', '601', '956', '736', '491', '825', '782', '51', '939', '347', '304', '677', '884', '236', '753', '116', '843', '564', '545', '783', '871', '264', '821', '566', '389', '822', '717', '574', '840', '784', '327', '948', '915', '644', '477', '749', '697', '471', '535', '676', '544', '2', '78', '498', '690', '364', '259', '826', '865', '819', '657', '391', '886', '436', '451', '25', '701', '186', '291', '898', '924', '740', '772', '371', '337', '570', '414', '412', '246', '288', '418', '691', '330', '429', '238', '814', '718', '317', '299', '734', '263', '278', '43', '817', '193', '666', '518', '654', '913', '949', '808', '935', '696', '123', '172', '228', '49', '586', '306', '583', '848', '911', '463', '293', '752', '368', '211', '323', '349', '380', '897', '277', '619', '406', '443', '531', '581', '683', '888', '543', '369', '815', '961', '766', '869', '503', '344', '658', '168', '269', '510', '703', '577', '88', '257', '184', '931', '312', '866', '669', '907', '62', '318', '268', '60', '48', '237', '693', '533', '456', '467', '321', '597', '818', '883', '336', '478', '760', '57', '475', '738', '715', '124', '453', '46', '358', '112', '852', '72', '23', '32', '604', '484', '39', '925', '158', '474', '374', '643', '422', '442', '214', '786', '851', '64', '614', '768', '616', '502', '8', '504', '287', '875', '466', '639', '681', '827', '302', '756', '202', '603', '872', '251', '511', '885', '446', '755', '394', '361', '704', '416', '448', '96', '512', '472', '454', '212', '828', '878', '216', '335', '28', '485', '863', '775', '735', '305', '295', '960', '86', '101', '201', '789', '34', '404', '427', '191', '342', '118', '85', '75', '341', '496', '232', '45', '105', '150', '392', '135', '906', '579', '628', '893', '455', '290', '356', '559', '24', '499', '265', '372', '790', '595', '891', '791', '940', '572', '762', '801', '793', '379', '731', '507', '297', '378', '626', '560', '47', '590', '529', '376', '103', '553', '218', '763', '562', '3', '360', '495', '445', '11', '106', '578', '205', '539', '400', '747', '950', '233', '962', '185', '320', '743', '431', '165', '692', '724', '629', '665', '571', '730', '479', '390', '133', '1', '254', '80', '423', '253', '662', '350', '136', '563', '434', '946', '29', '506', '127', '244', '834', '637', '917', '527', '741', '273', '370', '432', '716', '225', '239', '311', '388', '207', '182', '663', '401', '957', '555', '219', '385', '328', '134', '229', '903', '292', '196', '780', '285', '842', '770', '198', '520', '145', '381', '282', '296', '473', '449', '774', '489', '68', '928', '593', '568', '373', '882', '951', '745', '725', '671', '618', '709', '700', '274', '517', '334', '513', '301', '409', '286', '156', '90', '424', '44', '739', '131', '77', '732', '166', '351', '611', '340', '94', '440', '300', '83', '415', '329', '811', '799', '465', '556', '110', '241', '173', '910', '664', '526', '839', '831', '21', '411', '922', '641', '546', '447', '807', '16', '714', '149', '33', '602', '698', '270', '813', '797', '675', '152', '857', '667', '737', '530', '227', '630', '642', '141', '481', '250', '206', '800', '92', '167', '120', '785', '56', '396', '283', '10', '15', '99', '352', '333', '140', '441', '221', '322', '549', '870', '430', '937', '809', '522', '720', '631', '712', '169', '589', '91', '309', '399', '420', '450', '689', '912', '829', '339', '425', '314', '114', '733', '758', '437', '687', '806', '397', '900', '929', '802', '707', '902', '927', '195', '38', '30', '275', '146', '633', '722', '584', '405', '764', '190', '403', '258', '904', '315', '71', '955', '688', '338', '266', '224', '850', '695', '82', '289', '220', '408', '944', '307', '240', '65', '548', '905', '55', '812', '765', '680', '22', '19', '174', '346', '159', '357', '452', '959', '100', '625', '622', '13', '710', '493', '223', '787', '386', '122', '634', '938', '728', '413', '5', '107', '694', '324', '26', '387', '835', '460', '163', '0', '410', '194', '889', '113', '668', '849', '838']\n",
      "['1550', '1175', '1338', '1457', '1123', '1344', '1602', '1162', '1041', '1428', '1059', '1037', '1580', '1432', '1545', '1146', '1369', '1345', '1105', '1364', '1380', '1330', '1585', '1405', '1604', '998', '1368', '1166', '1235', '1603', '1540', '1250', '1421', '1267', '1388', '1284', '1256', '1436', '1342', '1173', '1159', '1444', '1254', '1080', '976', '1034', '1270', '970', '1318', '1089', '1316', '1446', '1262', '1539', '1464', '1016', '1063', '1093', '1298', '1070', '1239', '1168', '1398', '1197', '1169', '1356', '1384', '1289', '1103', '975', '1563', '1544', '1542', '1324', '1258', '993', '1508', '1413', '1274', '1128', '1042', '1536', '1068', '1535', '1408', '1520', '1210', '1601', '1500', '1121', '1485', '1058', '1100', '991', '1449', '990', '1164', '1620', '972', '1530', '1214', '1438', '1028', '1291', '1418', '1610', '1272', '1608', '1590', '1206', '1135', '1460', '1122', '1466', '1039', '1435', '1054', '1525', '1050', '1521', '1129', '1304', '1136', '1514', '1528', '1038', '1565', '1244', '1582', '1216', '1076', '1290', '1378', '1179', '1220', '1003', '1060', '1260', '1085', '1275', '1133', '985', '1387', '1456', '1066', '1373', '1293', '1561', '1571', '1591', '1209', '1305', '1611', '1459', '1020', '1422', '1120', '1224', '1494', '1309', '1595', '1522', '969', '997', '1017', '1013', '1568', '1313', '1355', '1379', '1329', '1447', '1589', '1243', '984', '1362', '1158', '1131', '1183', '1411', '1455', '1349', '1534', '1021', '1504', '1492', '1419', '1295', '1286', '1549', '1126', '1287', '1334', '1292', '1491', '1553', '1375', '1578', '1204', '1154', '1484', '1307', '1310', '1490', '1493', '1458', '1555', '1202', '1238', '1073', '1566', '1577', '1529', '1586', '1341', '1118', '1228', '1265', '1412', '1300', '1283', '1007', '1170', '1064', '1096', '1407', '1142', '1207', '1395', '1035', '1095', '1110', '1622', '1268', '1097', '1333', '1497', '1263', '1401', '1554', '1468', '1002', '1006', '1188', '1319', '1306', '1469', '1605', '1502', '1213', '1087', '1218', '1621', '1269', '1507', '1503', '1433', '1276', '1234', '1257', '1399', '1211', '1557', '1546', '1512', '1199', '1072', '1489', '1506', '1472', '1409', '983', '1278', '1026', '1029', '1056', '1351', '1511', '1251', '1303', '1022', '1531', '1226', '1461', '1397', '973', '1477', '1537', '1083', '1348', '1453', '971', '1332', '1187', '1483', '1416', '1574', '1495', '1572', '1336', '1425', '1215', '1000', '1393', '1410', '1196', '1057', '1011', '1463', '1424', '1614', '968', '1609', '1237', '1077', '1198', '1597', '1462', '1607', '1047', '1527', '1053', '1517', '1386', '1383', '1242', '1101', '1247', '1584', '1117', '1594', '1223', '1322', '1111', '1465', '1024', '1115', '1583', '1015', '1285', '1487', '1430', '1069', '1606', '1259', '1008', '1474', '1443', '1389', '1426', '1394', '1467', '1505', '1032', '1043', '1225', '1134', '1593', '981', '1480', '1579', '1045', '1012', '1296', '1071', '979', '1174', '1452', '1221', '1264', '1445', '1350', '1040', '1048', '1323', '1616', '1353', '1596', '1217', '1189', '1326', '1488', '1051', '1246', '1617', '1255', '1360', '1078', '1562', '1560', '1567', '1014', '1473', '1172', '1180', '1113', '1086', '1392', '1600', '1144', '1062', '1524', '1619', '1417', '1249', '974', '1277', '1184', '1576', '1366', '995', '1371', '1311', '1499', '1613', '1279', '1359', '1551', '1599', '964', '977', '1509', '1440', '1282', '1575', '1515', '966', '1297', '1381', '1099', '1331', '1161', '1533', '1112', '1415', '1280', '1519', '967', '1391', '1193', '1253', '1044', '1558', '1320', '1301', '1160', '1573', '1339', '1181', '1145', '1018', '1406', '1302', '1049', '1252', '1140', '1025', '1177', '1618', '1347', '1479', '1516', '1157', '1079', '1403', '1152', '1376', '1513', '1442', '978', '1203', '1030', '1201', '996', '1538', '1010', '1036', '1615', '1219', '1486', '1230', '1361', '1147', '1374', '1396', '1526', '1377', '1340', '1227', '1273', '1592', '1271', '1240', '1148', '1496', '1163', '1581', '1116', '1434', '1414', '1138', '1352', '1137', '1119', '1570', '1191', '1061', '980', '1107', '1001', '1321', '1404', '1471', '1153', '1588', '1308', '1354', '1130', '1372', '1357', '1084', '1088', '1150', '1423', '1143', '1448', '1222', '1470', '1439', '1543', '1266', '1081', '1475', '1437', '986', '1031', '1245', '1346', '1429', '1261', '1094', '1547', '1328', '1236', '1232', '1314', '987', '1090', '1454', '1065', '1098', '999', '1482', '1343', '1367', '1451', '1556', '1569', '1358', '1102', '1315', '1337', '1248', '1165', '1124', '1325', '1587', '1114', '1402', '1335', '1612', '1481', '1212', '1598', '1231', '1382', '1281', '1510', '1190', '1074', '1431', '994', '1141', '1194', '1552', '1370', '1033', '1441', '1476', '1046', '1312', '1548', '1104', '1241', '1156', '1559', '1075', '992', '1005', '1109', '1125', '1299', '1108', '1009', '965', '1004', '1139', '1167', '1518', '1151', '1327', '1055', '1171', '1427', '1067', '1363', '1186', '1176', '1149', '1400', '1420', '1229', '1091', '1185', '1019', '1390', '1182', '1127', '1205', '1523', '1365', '1178', '982', '1294', '1317', '1498', '1200', '1092', '1288', '1192', '1195', '1541', '1132', '1208', '1450', '1155', '1233', '1385', '1532', '1501', '1082', '989', '1106', '1564', '1052', '1027', '988', '1023', '1478']\n"
     ]
    }
   ],
   "source": [
    "import urllib3\n",
    "\n",
    "urllib3.disable_warnings()  # Disable SSL warnings that may happen during download.\n",
    "train_dataset = Dataset(training=True)\n",
    "test_dataset = Dataset(training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fb4a159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, axarr = plt.subplots(nrows=5, ncols=5, figsize=(20, 20))\n",
    "\n",
    "sample_keys = list(train_dataset.data.keys())\n",
    "\n",
    "for a in range(5):\n",
    "    for b in range(5):\n",
    "        temp_image = train_dataset.data[sample_keys[a]][b]\n",
    "        temp_image = np.stack((temp_image[:, :, 0],) * 3, axis=2)\n",
    "        temp_image *= 255\n",
    "        temp_image = np.clip(temp_image, 0, 255).astype(\"uint8\")\n",
    "        if b == 2:\n",
    "            axarr[a, b].set_title(\"Class : \" + sample_keys[a])\n",
    "        axarr[a, b].imshow(temp_image, cmap=\"gray\")\n",
    "        axarr[a, b].xaxis.set_visible(False)\n",
    "        axarr[a, b].yaxis.set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "186cfa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(x):\n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return layers.ReLU()(x)\n",
    "\n",
    "\n",
    "inputs = layers.Input(shape=(28, 28, 1))\n",
    "x = conv_bn(inputs)\n",
    "x = conv_bn(x)\n",
    "x = conv_bn(x)\n",
    "x = conv_bn(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(classes, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile()\n",
    "optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10010269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 1 0 2 3 0 2 4 0 4 2 3 1 3 1 1 4 4 4 1 3 1 1 2 3], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "batch 0: train=1.000000 test=0.600000\n",
      "tf.Tensor([4 2 2 2 3 0 4 3 0 2 1 0 0 0 1 3 1 0 2 1 0 4 4 2 2], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tf.Tensor([4 2 4 4 2 3 4 3 2 1 1 1 1 2 0 0 3 4 0 1 3 2 4 4 4], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tf.Tensor([3 1 3 1 4 0 3 1 0 3 2 0 0 3 0 3 2 3 1 1 2 2 0 0 4], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "tf.Tensor([2 0 2 3 4 3 4 0 1 0 4 0 4 0 4 2 4 3 4 4 1 2 2 0 1], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "tf.Tensor([0 1 4 2 4 3 0 3 4 1 3 4 0 0 0 1 3 2 0 0 1 1 3 0 4], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tf.Tensor([4 4 2 4 2 3 1 3 0 1 0 4 0 4 0 0 4 0 1 4 0 4 2 4 0], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "tf.Tensor([2 4 0 1 0 4 4 4 2 0 1 3 4 0 3 2 2 4 0 1 3 4 0 1 3], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tf.Tensor([1 0 2 1 3 1 2 0 3 3 3 3 4 1 3 2 4 2 0 3 2 2 2 1 4], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tf.Tensor([0 1 3 0 1 4 0 2 0 0 1 2 0 1 4 3 4 2 4 0 3 2 3 2 0], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tf.Tensor([0 0 2 0 4 3 3 1 1 0 4 2 4 4 4 4 3 0 4 1 1 0 1 1 0], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "tf.Tensor([0 4 1 0 3 4 0 1 3 2 4 2 1 1 2 4 1 2 4 3 2 1 3 2 0], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tf.Tensor([0 4 2 1 1 1 3 1 2 2 2 3 4 4 0 3 0 2 4 2 2 4 2 4 0], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "tf.Tensor([1 4 1 4 3 1 0 3 0 4 1 4 2 4 2 0 2 4 1 0 2 3 4 3 0], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tf.Tensor([0 1 3 3 3 4 1 1 4 2 1 2 0 3 3 4 3 1 3 2 2 1 1 3 2], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "tf.Tensor([3 1 1 1 3 2 3 4 0 3 0 3 3 4 0 1 2 0 4 3 3 0 2 0 2], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "tf.Tensor([2 3 2 1 1 4 1 1 3 2 3 1 2 4 2 1 0 4 3 3 3 3 1 0 1], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tf.Tensor([3 4 4 4 2 4 0 1 0 4 3 0 3 3 4 3 0 2 3 4 1 0 1 2 2], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tf.Tensor([4 3 0 4 0 4 1 2 3 2 1 3 1 4 1 3 4 4 3 2 4 2 0 1 2], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "tf.Tensor([2 2 3 4 1 4 3 2 2 1 4 0 4 4 1 4 3 0 4 3 0 0 3 1 2], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tf.Tensor([1 2 3 1 2 3 2 1 3 4 0 0 4 3 1 2 1 2 3 0 4 0 0 0 4], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tf.Tensor([2 0 4 0 4 2 1 1 3 2 2 2 4 1 0 2 0 4 1 4 2 3 4 3 0], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tf.Tensor([4 3 2 2 3 2 1 0 1 3 3 2 3 4 1 2 4 4 3 3 2 1 1 3 3], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tf.Tensor([1 3 2 3 2 0 3 2 3 4 4 2 2 0 0 1 2 4 4 3 0 3 1 4 1], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tf.Tensor([3 3 2 2 2 3 2 1 4 1 3 3 0 3 1 2 4 2 3 4 1 2 2 1 2], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tf.Tensor([0 0 1 2 4 3 1 2 4 3 1 0 3 2 3 2 2 0 1 2 2 3 1 0 1], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tf.Tensor([0 3 0 3 2 1 2 0 2 4 4 1 0 3 1 2 4 0 1 2 4 4 2 2 4], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tf.Tensor([1 4 1 3 2 2 0 1 1 2 4 0 4 1 2 3 2 3 4 4 4 2 3 4 3], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tf.Tensor([1 4 2 2 1 4 0 1 1 0 2 0 4 0 3 4 4 2 2 4 1 4 1 1 4], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tf.Tensor([2 0 0 4 2 3 1 2 2 2 4 0 1 3 0 1 2 0 1 4 4 1 2 4 2], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tf.Tensor([3 3 1 3 3 0 2 1 4 2 0 3 2 0 2 2 0 3 0 1 3 2 2 3 3], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "tf.Tensor([3 3 4 3 1 2 1 1 2 2 3 3 1 4 4 3 1 1 1 4 1 2 2 4 0], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "tf.Tensor([4 3 1 4 2 0 1 1 3 4 1 3 0 0 1 0 2 3 0 0 4 4 2 3 0], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tf.Tensor([1 0 0 0 2 3 0 1 1 2 0 3 3 0 2 4 2 0 3 0 3 4 1 0 4], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tf.Tensor([1 2 2 2 0 3 3 1 1 3 0 2 3 4 0 3 0 2 3 2 0 3 3 4 1], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "tf.Tensor([4 3 0 1 3 4 2 1 1 4 4 2 3 4 1 0 3 3 2 3 2 1 0 2 0], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tf.Tensor([3 3 0 2 1 4 2 1 3 0 0 0 2 1 1 3 4 4 0 2 1 3 4 2 3], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "tf.Tensor([4 3 2 2 3 3 1 1 2 0 1 1 0 0 2 4 3 0 3 2 3 4 4 2 3], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "tf.Tensor([3 1 0 4 3 3 0 3 2 2 3 2 0 2 3 4 1 1 0 1 3 0 4 0 4], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tf.Tensor([3 3 2 0 0 3 2 3 3 1 0 2 4 0 0 0 2 3 0 4 4 0 1 2 0], shape=(25,), dtype=int32)\n",
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         loss \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39msparse_categorical_crossentropy(labels, preds)\n\u001b[1;32m     42\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_weights)\n\u001b[0;32m---> 43\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_weights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m test_preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_images)\n\u001b[1;32m     45\u001b[0m test_preds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39margmax(test_preds)\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/miniconda3/envs/model_inversion/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py:678\u001b[0m, in \u001b[0;36mOptimizerV2.apply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    675\u001b[0m   grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_gradients(grads_and_vars)\n\u001b[1;32m    676\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_gradients(grads_and_vars)\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_merge_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunctools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_apply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapply_state\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/model_inversion/lib/python3.9/site-packages/tensorflow/python/distribute/merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m  The return value of the `fn` call.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[0;32m---> 51\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m distribution_strategy_context\u001b[38;5;241m.\u001b[39mget_replica_context()\u001b[38;5;241m.\u001b[39mmerge_call(\n\u001b[1;32m     54\u001b[0m       fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/model_inversion/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py:715\u001b[0m, in \u001b[0;36mOptimizerV2._distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, apply_state, name)\u001b[0m\n\u001b[1;32m    713\u001b[0m eagerly_outside_functions \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mexecuting_eagerly_outside_functions()\n\u001b[1;32m    714\u001b[0m update_ops \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 715\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m name_scope_only_in_function_or_graph(name \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name):\n\u001b[1;32m    716\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m grad, var \u001b[38;5;129;01min\u001b[39;00m grads_and_vars:\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;66;03m# Colocate the update with variables to avoid unnecessary communication\u001b[39;00m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;66;03m# delays. See b/136304694.\u001b[39;00m\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m distribution\u001b[38;5;241m.\u001b[39mextended\u001b[38;5;241m.\u001b[39mcolocate_vars_with(var):\n",
      "File \u001b[0;32m~/miniconda3/envs/model_inversion/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py:70\u001b[0m, in \u001b[0;36mNullContextmanager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     68\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     71\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, type_arg, value_arg, traceback_arg):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training = []\n",
    "testing = []\n",
    "for meta_iter in range(meta_iters):\n",
    "    frac_done = meta_iter / meta_iters\n",
    "    cur_meta_step_size = (1 - frac_done) * meta_step_size\n",
    "    # Temporarily save the weights from the model.\n",
    "    old_vars = model.get_weights()\n",
    "    # Get a sample from the full dataset.\n",
    "    mini_dataset = train_dataset.get_mini_dataset(\n",
    "        inner_batch_size, inner_iters, train_shots, classes\n",
    "    )\n",
    "    for images, labels in mini_dataset:\n",
    "        print(labels)\n",
    "        break\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = model(images)\n",
    "            loss = keras.losses.sparse_categorical_crossentropy(labels, preds)\n",
    "        grads = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    new_vars = model.get_weights()\n",
    "    # Perform SGD for the meta step.\n",
    "    for var in range(len(new_vars)):\n",
    "        new_vars[var] = old_vars[var] + (\n",
    "            (new_vars[var] - old_vars[var]) * cur_meta_step_size\n",
    "        )\n",
    "    # After the meta-learning step, reload the newly-trained weights into the model.\n",
    "    model.set_weights(new_vars)\n",
    "    # Evaluation loop\n",
    "    if meta_iter % eval_interval == 0:\n",
    "        accuracies = []\n",
    "        for dataset in (train_dataset, test_dataset):\n",
    "            # Sample a mini dataset from the full dataset.\n",
    "            train_set, test_images, test_labels = dataset.get_mini_dataset(\n",
    "                eval_batch_size, eval_iters, shots, classes, split=True\n",
    "            )\n",
    "            old_vars = model.get_weights()\n",
    "            # Train on the samples and get the resulting accuracies.\n",
    "            for images, labels in train_set:\n",
    "                with tf.GradientTape() as tape:\n",
    "                    preds = model(images)\n",
    "                    loss = keras.losses.sparse_categorical_crossentropy(labels, preds)\n",
    "                grads = tape.gradient(loss, model.trainable_weights)\n",
    "                optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "            test_preds = model.predict(test_images)\n",
    "            test_preds = tf.argmax(test_preds).numpy()\n",
    "            num_correct = (test_preds == test_labels).sum()\n",
    "            # Reset the weights after getting the evaluation accuracies.\n",
    "            model.set_weights(old_vars)\n",
    "            accuracies.append(num_correct / classes)\n",
    "        training.append(accuracies[0])\n",
    "        testing.append(accuracies[1])\n",
    "        if meta_iter % 100 == 0:\n",
    "            print(\n",
    "                \"batch %d: train=%f test=%f\" % (meta_iter, accuracies[0], accuracies[1])\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4beea1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(105, 105, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfds.load(\"omniglot\", split=\"small2\", as_supervised=True, shuffle_files=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87bf6c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in mini_dataset:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c165f9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([25, 28, 28, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c7c2dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([25])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b94f0cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2fe9174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([25, 5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28d08b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(25,), dtype=float32, numpy=\n",
       "array([1.9235716 , 3.3748648 , 1.0147865 , 3.0546052 , 1.0147865 ,\n",
       "       0.6430838 , 0.99476004, 2.2709763 , 1.0219028 , 1.4968102 ,\n",
       "       2.097036  , 1.671476  , 1.972186  , 1.9084604 , 1.9192832 ,\n",
       "       3.0546052 , 2.9377275 , 1.4968102 , 1.3239068 , 1.5131507 ,\n",
       "       1.0227842 , 1.972186  , 1.5535084 , 1.1110704 , 3.374865  ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.losses.sparse_categorical_crossentropy(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c34e08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
